{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TemporalStyleNet - Exploration Notebook\n",
    "\n",
    "This notebook demonstrates the core functionality of the TemporalStyleNet project.\n",
    "\n",
    "**Topics covered:**\n",
    "1. Loading and preprocessing data\n",
    "2. Style transfer on single images\n",
    "3. Video processing with temporal consistency\n",
    "4. Evaluation metrics\n",
    "5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.models.style_transfer import StyleTransferNet\n",
    "from src.models.temporal_consistency import TemporalConsistencyModule\n",
    "from src.inference.video_processor import VideoStyleTransfer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single Image Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = StyleTransferNet().to(device)\n",
    "model.eval()\n",
    "\n",
    "# Image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load images (replace with your paths)\n",
    "content_img = Image.open('../data/videos/sample_frame.jpg').convert('RGB')\n",
    "style_img = Image.open('../data/styles/starry_night.jpg').convert('RGB')\n",
    "\n",
    "content_tensor = transform(content_img).unsqueeze(0).to(device)\n",
    "style_tensor = transform(style_img).unsqueeze(0).to(device)\n",
    "\n",
    "print(f\"Content shape: {content_tensor.shape}\")\n",
    "print(f\"Style shape: {style_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply style transfer\n",
    "with torch.no_grad():\n",
    "    stylized = model(content_tensor, style_tensor, alpha=1.0)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(content_img)\n",
    "axes[0].set_title('Content')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(style_img)\n",
    "axes[1].set_title('Style')\n",
    "axes[1].axis('off')\n",
    "\n",
    "stylized_img = stylized.squeeze(0).cpu().clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "axes[2].imshow(stylized_img)\n",
    "axes[2].set_title('Stylized')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video processor\n",
    "processor = VideoStyleTransfer(\n",
    "    method='adain',\n",
    "    device='cuda',\n",
    "    use_temporal_consistency=True\n",
    ")\n",
    "\n",
    "# Process video\n",
    "stats = processor.process_video(\n",
    "    input_path='../data/videos/input.mp4',\n",
    "    style_path='../data/styles/starry_night.jpg',\n",
    "    output_path='../data/outputs/stylized_notebook.mp4',\n",
    "    alpha=0.8,\n",
    "    max_frames=50  # Process first 50 frames for testing\n",
    ")\n",
    "\n",
    "print(\"\\nProcessing Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temporal Consistency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.temporal_consistency import compute_temporal_consistency_metrics\n",
    "\n",
    "# Load video frames\n",
    "frames, fps, (width, height) = processor.load_video('../data/outputs/stylized_notebook.mp4')\n",
    "\n",
    "# Convert to tensor\n",
    "frames_tensor = torch.stack([\n",
    "    torch.from_numpy(f).permute(2, 0, 1).float() / 255.0\n",
    "    for f in frames[:50]\n",
    "])\n",
    "\n",
    "# Compute metrics\n",
    "metrics = compute_temporal_consistency_metrics(frames_tensor)\n",
    "\n",
    "print(\"\\nTemporal Consistency Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Different Alpha Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different style strengths\n",
    "alphas = [0.3, 0.6, 1.0]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(alphas) + 1, figsize=(20, 5))\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(content_img)\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Different alphas\n",
    "for i, alpha in enumerate(alphas):\n",
    "    with torch.no_grad():\n",
    "        stylized = model(content_tensor, style_tensor, alpha=alpha)\n",
    "    \n",
    "    stylized_img = stylized.squeeze(0).cpu().clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "    axes[i + 1].imshow(stylized_img)\n",
    "    axes[i + 1].set_title(f'Î± = {alpha}')\n",
    "    axes[i + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark processing speed\n",
    "num_runs = 10\n",
    "times = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(content_tensor, style_tensor)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    times.append(elapsed)\n",
    "\n",
    "avg_time = np.mean(times)\n",
    "fps = 1.0 / avg_time\n",
    "\n",
    "print(f\"\\nPerformance Benchmarks:\")\n",
    "print(f\"  Average time: {avg_time:.3f}s\")\n",
    "print(f\"  FPS: {fps:.2f}\")\n",
    "print(f\"  Std Dev: {np.std(times):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export for Resume\n",
    "\n",
    "Key metrics to include in your resume:\n",
    "- Processing speed (FPS)\n",
    "- Temporal consistency improvement\n",
    "- Model parameters\n",
    "- Multi-GPU speedup (if trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nModel Statistics:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Processing speed: {fps:.2f} FPS\")\n",
    "print(f\"  Temporal stability: {metrics['stability_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Training**: Use `scripts/train.py` to train your own model\n",
    "2. **Evaluation**: Run comprehensive benchmarks with `scripts/benchmark.py`\n",
    "3. **Demo**: Launch interactive demo with `demo/app.py`\n",
    "4. **Production**: Deploy with your favorite framework\n",
    "\n",
    "For more information, see the [README](../README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
